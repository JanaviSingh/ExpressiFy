{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c65e4-a5d8-41cd-a9e0-9d8a9adb7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295984e-8c08-4624-a305-55f284a710b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"images/train/\"\n",
    "TEST_DIR = \"images/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d240140-9fe1-429c-b6a1-db39add5fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24436e-3349-4cec-b472-a03b252d684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de703d-c8af-4170-a32b-468313820214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b3240-3598-42df-8577-1606e79f0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c98d6-3030-41e7-b86d-fb24c62192e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cccd81-4db3-4386-b1b4-49f7198a322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75093946-d3fc-4352-984c-27062c0301bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,grayscale =  True )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c602e6-9005-4730-8eed-d43f8e8f855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(train['image']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f12cd4-2ef8-41d8-9877-2b36750c94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3ca67-5bf9-4a74-9d52-56f859de630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396143e-f5ea-4f24-911f-9e102ae9353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6b25e-e6e6-4c31-a74e-8ba7d68893c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6833c-8343-408a-ac1a-13ee324fa42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca4bac-d5ff-48c7-b406-e1b22993271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba8a91-5246-45cb-99c6-d3c065cf503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "model = Sequential()\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "BatchNormalization()\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "BatchNormalization()\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "BatchNormalization()\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "BatchNormalization()\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84599e-bfa4-42d6-bece-f4856d42fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25505d91-f159-46c2-8efc-cec59c4fb719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "model.compile(optimizer=AdamW(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209eaf1-0070-4499-b571-96f15e4ce15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b99449-2b2e-4f78-84fb-e6d279d9603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define Sequential Model\n",
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Layer (with Input Shape)\n",
    "model.add(Conv2D(64, (3,3), activation='relu', input_shape=(48, 48, 1)))  # Ensure input shape is correct\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "# Second Convolutional Layer\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "# Third Convolutional Layer (Increase Complexity)\n",
    "model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "# Fourth Convolutional Layer (Increase Depth)\n",
    "model.add(Conv2D(512, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "# Flatten Layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Helps prevent overfitting\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))  # Assuming 7 emotion classes\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46295f40-1d98-4785-927d-dfecef972de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140dfcd-9b46-435a-91ba-10282686a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,      # Rotate images up to 20 degrees\n",
    "    width_shift_range=0.2,  # Shift width by 20% of the image width\n",
    "    height_shift_range=0.2, # Shift height by 20% of the image height\n",
    "    zoom_range=0.2,         # Zoom into images by 20%\n",
    "    horizontal_flip=True,   # Flip images horizontally\n",
    "    fill_mode='nearest'     # Fill pixels after transformation\n",
    ")\n",
    "# Fit the generator to the training data\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063bacc-b035-4176-83bf-7dc017e8356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the augmented data\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=100), \n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=50,\n",
    "          callbacks=[early_stopping, lr_scheduler])  # Add other callbacks if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85336a-5b5c-4c16-9c72-977232f29f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x= x_train,y = y_train, batch_size = 300, epochs = 30, validation_data = (x_test,y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eba1d2-4ec1-4ac3-a649-7c45607c93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa31811-3783-46b5-9107-59d57d1eb912",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1323cb-b7f0-4432-9c79-0eb9f7a5c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74490460-036a-49d0-ad83-9df1156c06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"emotiondetector.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e4e170-cca2-4dfd-8653-f840e59919b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb89b0b-703b-42ef-ae18-fc51d5b692b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,grayscale =  True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13482b6-a94e-404a-b479-d809391ce0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43b91d-e369-44ec-ad07-3531d2b99685",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24513820-fce4-4a4b-84df-de62de22d8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = 'images/train/fear/2.jpg'\n",
    "print(\"original image is of fear\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09fd36-0753-4029-b532-f6d12c358010",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/disgust/299.jpg'\n",
    "print(\"original image is of disgust\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e4e155-12a4-495c-acc7-2a30011923a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/happy/7.jpg'\n",
    "print(\"original image is of happy\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2d94c-9535-47cd-becb-dfcb243b9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/surprise/15.jpg'\n",
    "print(\"original image is of surprise\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9f5d3-348e-44af-b266-e819dd0750cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
